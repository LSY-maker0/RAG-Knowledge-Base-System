"""
main - fastapi å…¥å£æ–‡ä»¶

Author: lsy
Date: 2026/1/22
"""
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
import json
import asyncio
from src.retrieval import HybridRetriever
from pathlib import Path

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # å…è®¸æ‰€æœ‰æ¥æºï¼ˆç”Ÿäº§ç¯å¢ƒå»ºè®®å†™æ­»å…·ä½“å‰ç«¯åœ°å€ï¼Œå¦‚ ["http://localhost:5173"]ï¼‰
    allow_credentials=True,
    allow_methods=["*"],  # å…è®¸æ‰€æœ‰ HTTP æ–¹æ³•
    allow_headers=["*"],  # å…è®¸æ‰€æœ‰è¯·æ±‚å¤´
)

# 1. å®šä¹‰è¯·æ±‚ä½“çš„æ•°æ®æ¨¡å‹
class QuestionRequest(BaseModel):
    question: str

def retrieval_chunks(question):
    retrieval = HybridRetriever(vector_index_path=Path('data/stock_data/databases/vector_dbs/all_reports.faiss'),metadata_path=Path('data/stock_data/databases/vector_dbs/all_metadata.json'))
    relevant_chunks = retrieval.hybrid_retriever_chunks(question=question, llm_reranking_sample_size=20)
    print(relevant_chunks)
    return relevant_chunks

# 2. æ¨¡æ‹Ÿä¸€ä¸ªæµå¼ç”Ÿæˆæ•°æ®çš„å‡½æ•° (ä½ å¯ä»¥æŠŠè¿™é‡Œæ›¿æ¢æˆçœŸå®çš„ LLM è°ƒç”¨)
async def generate_rag_response(question: str):
    """
    é€‚é… RAGInterface.vue çš„åç«¯æµå¼ç”Ÿæˆå‡½æ•°
    """

    # --- æ­¥éª¤ 1: æ¥æ”¶é—®é¢˜ ---
    yield {
        "type": "input",
        "content": {
            "type": "input",
            "title": "ğŸ“¥ æ¥æ”¶é—®é¢˜",
            "data": f"æ”¶åˆ°ç”¨æˆ·é—®é¢˜: {question}",
            "time": "T+0.00s"
        }
    }

    # --- æ­¥éª¤ 2: æ£€ç´¢ ---
    relevant_chunks = retrieval_chunks(question=question)

    yield {
        "type": "retrieval",
        "content": {
            "type": "retrieval",
            "title": "ğŸ” æ£€ç´¢é˜¶æ®µ",
            "data": ["æ­£åœ¨è¿æ¥ Elasticsearch...", "æ‰§è¡Œè¯­ä¹‰å‘é‡æ£€ç´¢..."],
            "description": "æ­£åœ¨ä»çŸ¥è¯†åº“æ£€ç´¢ç›¸å…³æ–‡æ¡£...",
            "time": "T+0.50s"
        }
    }

    # --- å‘é€å‚è€ƒæ–‡æ¡£ ---
    yield {
        "type": "rerank",
        "content": {
            "type": "rerank",
            "title":'ğŸ§  LLMé‡æ’é˜¶æ®µ',
            "data": relevant_chunks,
            "time": "T+0.50s"
        }
    }

    # --- æ­¥éª¤ 3: ç”Ÿæˆç­”æ¡ˆ (æ‰“å­—æœºæ•ˆæœ) ---
    # TODO: è¿™é‡Œæ›¿æ¢æˆçœŸå®çš„ LLM è°ƒç”¨
    answer_text = "ä¸­èŠ¯å›½é™…åœ¨æ™¶åœ†åˆ¶é€ è¡Œä¸šä¸­å…·æœ‰æ˜¾è‘—çš„åœ°ä½ï¼Œæ˜¯ä¸–ç•Œé¢†å…ˆçš„é›†æˆç”µè·¯æ™¶åœ†ä»£å·¥ä¼ä¸šä¹‹ä¸€ã€‚"


    for char in answer_text:
        await asyncio.sleep(0.05)
        yield {
            "type": "answer",
            "data": char
        }

    # --- ç»“æŸ ---
    yield {
        "type": "done",
        "timing": "æ€»è€—æ—¶: 3.0 ç§’"
    }


# è¾…åŠ©å‡½æ•°ï¼šå°†å­—å…¸è½¬æ¢ä¸º SSE æ ¼å¼ (data: {...}\n\n)
async def event_generator(question: str):
    """ç”Ÿæˆ SSE æ ¼å¼çš„æµæ•°æ®"""
    async for chunk in generate_rag_response(question):
        json_str = json.dumps(chunk, ensure_ascii=False)
        # æ ‡å‡† SSE æ ¼å¼
        yield f"data: {json_str}\n\n"


# 3. å®šä¹‰æ¥å£
@app.post("/query")
async def chat_endpoint(request: QuestionRequest):
    """
    æµå¼èŠå¤©æ¥å£ - è¾¹ç”Ÿæˆè¾¹ä¼ è¾“
    """
    return StreamingResponse(
        event_generator(request.question),  # ä¼ å…¥ç”¨æˆ·çš„é—®é¢˜
        media_type="text/event-stream"  # æŒ‡å®šåª’ä½“ç±»å‹ä¸º SSE
    )


# è¿è¡ŒæœåŠ¡å™¨
if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="127.0.0.1", port=8000)
