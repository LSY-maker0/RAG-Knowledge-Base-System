"""
questions_processing - é—®é¢˜å¤„ç†å™¨

Author: lsy
Date: 2026/1/7
"""
import time
from pathlib import Path

from src.api_requests import APIProcessor
from src.retrieval import VectorRetriever
from src.retrieval import HybridRetriever

class QuestionsProcessor:
    def __init__(
        self,
        llm_ranking:bool=False,
        api_provider:str="dashscope",
        answering_model:str="qwen-turbo-lastest",
        vector_index_path:Path=None,
        metadata_path:Path=None,
    ):
        self.llm_ranking = llm_ranking
        self.api_provider = api_provider
        self.answering_model = answering_model
        self.vector_index_path = vector_index_path
        self.metadata_path = metadata_path
        self.api_processor = APIProcessor(provider=self.api_provider)

    # def __format_retrieval_results(self, retrieval_results) -> str:
    #     """å°†æ£€ç´¢ç»“æœè½¬åŒ–ä¸ºRAGä¸Šä¸‹æ–‡å­—ç¬¦ä¸²ï¼Œä¼˜åŒ–å¤§æ¨¡å‹ç†è§£"""
    #     context_parts = []
    #
    #     # éå†æ£€ç´¢å‡ºçš„æ¯ä¸€ä¸ªå—
    #     for idx, chunk in enumerate(retrieval_results):
    #         # 1. æå–å…³é”®ä¿¡æ¯
    #         vector_score = chunk.get('vector_score', 0)
    #         bm25_score = chunk.get('bm25_score', 0)
    #         final_score = chunk.get('final_score', 0)
    #         file_name = chunk.get('file_origin', 'æœªçŸ¥æ–‡ä»¶')
    #         page_range = chunk.get('page_range', [])
    #         text_content = chunk.get('text', '')
    #
    #         # 2. æ ¼å¼åŒ–é¡µç ä¿¡æ¯ (ä¾‹å¦‚ï¼šP34-35)
    #         page_info = f"P{page_range[0]}" if page_range else "æœªçŸ¥é¡µç "
    #         if len(page_range) > 1:
    #             page_info += f"-{page_range[-1]}"
    #
    #         # 3. æ„å»ºæ¯ä¸ªå—çš„å±•ç¤ºæ–‡æœ¬
    #         # ä½¿ç”¨ >>> ç¬¦å·ä½œä¸ºè§†è§‰åˆ†éš”ç¬¦ï¼Œå¸®åŠ©æ¨¡å‹åŒºåˆ†ä¸åŒå¼•ç”¨å—
    #         chunk_text = f"""
    # [å‚è€ƒæ–‡æ¡£ {idx + 1}] (å‘é‡åˆ†æ•°: {vector_score})(bm25åˆ†æ•°: {bm25_score})(åŠ æƒåˆ†æ•°: {final_score})
    # ğŸ“‚ æ¥æºæ–‡ä»¶: {file_name}
    # ğŸ“„ é¡µç : {page_info}
    # ---------------
    # {text_content}
    # """
    #         context_parts.append(chunk_text)
    #
    #     # 4. æ‹¼æ¥æ‰€æœ‰å—ï¼Œä½œä¸ºæ•´ä½“ä¸Šä¸‹æ–‡
    #     rag_text = "\n".join(context_parts)
    #     return rag_text

    def __format_retrieval_results(self, retrieval_results) -> str:
        """å°†æ£€ç´¢ç»“æœè½¬åŒ–ä¸ºRAGä¸Šä¸‹æ–‡å­—ç¬¦ä¸²ï¼Œä¼˜åŒ–å¤§æ¨¡å‹ç†è§£"""
        context_parts = []

        # éå†æ£€ç´¢å‡ºçš„æ¯ä¸€ä¸ªå—
        for idx, chunk in enumerate(retrieval_results):
            # 1. æå–å…³é”®ä¿¡æ¯
            # åªä¿ç•™é‡æ’åçš„ç›¸å…³æ€§åˆ†æ•°
            relevance_score = chunk.get('relevance_score', 0)
            reasoning = chunk.get('reasoning', '')
            file_name = chunk.get('file_origin', 'æœªçŸ¥æ–‡ä»¶')
            page_range = chunk.get('page_range', [])
            text_content = chunk.get('text', '')

            # 2. æ ¼å¼åŒ–é¡µç ä¿¡æ¯ (ä¾‹å¦‚ï¼šP34-35)
            page_info = f"P{page_range[0]}" if page_range else "æœªçŸ¥é¡µç "
            if len(page_range) > 1:
                page_info += f"-{page_range[-1]}"

            # 3. æ„å»ºæ¯ä¸ªå—çš„å±•ç¤ºæ–‡æœ¬
            # åªæ˜¾ç¤ºé‡æ’åçš„åˆ†æ•°
            chunk_text = f"""
    [å‚è€ƒæ–‡æ¡£ {idx + 1}] (ç›¸å…³åº¦: {relevance_score:.2f})
    ğŸ“‚ æ¥æºæ–‡ä»¶: {file_name}
    ğŸ“„ é¡µç : {page_info}
    ğŸ’¡ åŒ¹é…åŸå› : {reasoning}
    ---------------
    {text_content}
    """
            context_parts.append(chunk_text)

        # 4. æ‹¼æ¥æ‰€æœ‰å—ï¼Œä½œä¸ºæ•´ä½“ä¸Šä¸‹æ–‡
        rag_text = "\n".join(context_parts)
        return rag_text

    def process_single_question(self,question:str,kind:str) -> dict:
        """å•æ¡é—®é¢˜æ¨ç†ï¼Œè¿”å›ç»“æ„åŒ–ç­”æ¡ˆ"""
        # retrieval=Hybridretrieval()
        # retrieval=VectorRetriever(vector_index_path=self.vector_index_path,metadata_path=self.metadata_path)
        print(f"{'=' * 20} å¼€å§‹ RAG æµç¨‹ {'=' * 20}")
        print(f"ç”¨æˆ·é—®é¢˜: {question}\n")
        retrieval=HybridRetriever(vector_index_path=self.vector_index_path,metadata_path=self.metadata_path)
        relevant_chunks = retrieval.hybrid_retriever_chunks(question=question,llm_reranking_sample_size=20)

        rag_context = self.__format_retrieval_results(relevant_chunks)
        print(rag_context)
        t0=time.time()
        print(f"\n[é˜¶æ®µ 3/3] ç”Ÿæˆæœ€ç»ˆå›ç­”...")
        answer_dict = self.api_processor.get_answer_from_rag_context(
            question=question,
            rag_context=rag_context,
            kind=kind,
            model=self.answering_model
        )
        t1 = time.time()
        print(f"  -> æ¨¡å‹è°ƒç”¨ã€è€—æ—¶ï¼š {t1-t0:.2f} ç§’ã€‘")
        return answer_dict
